<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
    
    <meta name="description" content="Vy Vo">
    <meta property="og:description" content="Causal Data Science: A Beginner Guide"/>
    <meta property="og:image" content="https://isvy08.github.io/icon/vv.png"/>
    <title>Identification of Causal Effects</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="../main.css">
</head>

<body>

    <div class="wrapper-masthead">
        <div class="container">
          <header class="masthead clearfix">
            <a href="https://isvy08.github.io/" class="site-avatar"><img src="../icon/vv.png" /></a>
  
            <div class="site-info">
              <h1 class="site-name"><a href="https://isvy08.github.io/causal-data-science/">Causal Data Science: A Beginner Guide</a></h1>
              <p class="site-description">A Quick Tutorial to Causal Inference in Practice </p>
            </div>

          </header>
          <br>
          <div class="topnav">
            <a href="causal-data-science/">About</a>
            <a class="active">Fundamentals</a>
            <a href="#">&#128274  Experimentation </a>
            <a href="#">&#128274  Tools</a>
            <a href="#">&#128274  Applications</a>
          </div>
        </div>
      </div>


    <div id="main" role="main" class="container">
      <h2 id="2">Chapter 2. Identification of Causal Effects</h2>
      <article class="post" style="text-align: justify;">
        
        <p>
          Assume we are given an observational dataset of \(V\) <span style="text-decoration: underline;">observed</span> variables and causal graph \(G\). The set \(V\) includes a treatment variable \(X\) and a outcome variable \(Y\) of interest, 
          and we wish to determine the effect on \(Y\) under the intervention \(do(X=x)\) â€“ that is, to estimate the interventional distribution \(P(y|do(x)\)).
        <p>
        <p>
         Recall that \(X\) and \(Y\) are not neccessarily single variables, rather each of them can be a subset of \(n\) variables in \(V\) and mathematically represented as an \(n\)-dimensional vector. 
         Identification methods can be broadly categorized as <strong>Non-parametric</strong> or <strong>Parametric</strong>. 
        </p>
        <div class="toc">
          <h5 style="text-decoration: underline" >Table of Contents</h5>
          <h6>Non-parametric methods</h6>
          <ul>
            <a href="#2.1"><li>2.1. Back-Door Criterion</li></a>
            <a href="#2.2"><li>2.2. Front-Door Criterion</li></a>
            <a href="#2.3"><li>2.3. \(Do-\)Calculus</li></a>
          </ul>
          <h6>Parametric methods</h6>
          <ul>
            <a href="#2.4"><li>2.4. Structural Causal Models</li></a>
            <a href="#2.5"><li>2.5. Instrumental Variables</li></a>
            <a href="#2.6"><li>2.6. Mediation Analysis</li></a>
          </ul>
        </div>
        <p>        
        Under certain conditions, these methods allow us to estimate \(P(y|do(x))\) (i.e., a <strong>causal estimand</strong>) from statistical quantities to be computed directly from the data.
        The idea is to pass the causal estimand through a series of transformations that output an equivalent combination of statistical estimands, 
        which must be derived from plausible probability rules based on the assumptions and properties we have discussed so far.   
        </p>

        <h3 id="2.1">2.1. Back-Door Criterion</h3>
        <div class="theorem">
          <h5>Back-Door Criterion Definition (Pearl 2009):</h5>
          A set of variables \(Z\) in \(V\) satisfies the back-door criterion relative to \(X\) and \(Y\) in a DAG \(G\) if
          <ul>
            <li>no node in \(Z\) is a descendent of \(X\)</li>
            <li>\(Z\) blocks every path between \(X\) and \(Y\) that contains an arrow into \(X\)</li>
          </ul>
        </div>
        <p>This definition is followed by</p>
        <div class="theorem">
          <h5>Back-Door Adjustment Theorem (Pearl 2009):</h5>
          If \(Z\) satisfies the back-door criterion relative to (\(X,Y\)), the causal effect of \(X\) on \(Y\) is identified as
          $$P(y|do(x)) = \sum_{z}P(y|x,z)P(z)$$
        </div>
        <p>
          The theorem aligns with our intuition above: If \(Z\) blocks all back-door paths between \(X\) and \(Y\), there will be no confounding biases, 
          thus rendering any associational effects be the true causal effect. Figure 1.2 is a simple example where \(Z\) is a back-door criterion.
          And when doing intervention, we estimated the effect based on the manipulated graph, in which the incoming edge into \(X\) from \(Z\) is removed. 
          I provide a step-by-step proof to solidify the intuition.  
        </p>
        <figure style="text-align: center;">
          <img src='figures/1-1-Fig2.png' alt='graphs' width="300" />
          <figcaption style="font-size: small;">Figure 1.2: Confounder</figcaption>
        </figure>
        <p>
          <ol type="i">
            <li>By probability rules, 
              $$P(y|do(x)) = \frac{P(y,do(x))}{P(do(x))} = \frac{\sum_{z}P(y,do(x),z)}{P(do(x))} = \frac{\sum_{z}P(y|do(x),z)P(do(x),z)}{P(do(x))}$$ 
              $$= \frac{\sum_{z}P(y|do(x),z)P(z|do(x))P(do(x))}{P(do(x))} = \sum_{z}P(y|do(x),z)P(z|do(x))) $$
            </li>
            <li> 
              By <strong>Modularity assumption</strong>, \(Y\) is not the intervention node so \(P(y|pa_y)\) under the intervention remains unchanged. 
              This yields \(P(y|do(x),z) = P(y|x, z)\). This equality holds even when \(Z\) is not the parent of \(Y\) but still satisfies the back-door criterion.
            </li><br>
            <li>
              Assume there are no other back-door paths \(X-Z\), \(Z\) does not depend on \(X\), so \(P(z|do(x))=P(z)\). 
              This is justified by observing that \(Z\) is independent of \(do(x)\) in the manipulated graph, but <strong>not</strong> independent of \(X\).
              Notice that you could also have directly derived \(P(do(x),z) = P(do(x))P(z)\) due to this non-dependency.
            </li>
          </ol>
          Steps (1), (2) and (3) together yield the theorem. We can also see that \(P(y|do(x)) \ne P(y|X=x)\) since \(P(x,z) \ne P(x)P(z)\). 
          Here is a more complicated example borrowed from the <i>Book of Why</i> (Pearl & Mackenzie, 2018, pp.162)
        </p>  
          <figure style="text-align: center;">
            <img src='figures/1-2-Fig1.png' alt='backdoor-criterion' width="300" />
            <figcaption style="font-size: small;">Figure 2.1</figcaption>
          </figure>
        <p>
          There are two paths with arrows pointing into \(X\): \(X \leftarrow A \rightarrow B \leftarrow C \rightarrow Y\) and \(X \leftarrow B \leftarrow C \rightarrow Y\).
          If we condition on \(B\) to block the second path, it opens up the first back-door path since \(B\) is a collider. We therefore must further control for \(A,C\).
          However, we can also only control for \(C\) to block the second path while the leaving the first path already been blocked by \(B\). 
          Thus, the back-door criterion is either \(C\) or the set {\(A,B,C\)}.   
        </p>
        <h3 id="2.2">2.2. Front-Door Criterion</h3>
        <p>
          Assume we have a graph \(G\) as follow, where the confounder \(Z\) is unobserved. Thus, blocking the back-door is impossible.  
          Fortunately, we can take advantage of such a variable as \(M\) - a mediator such that all causal paths from \(X\) to \(Y\) must go through \(M\). 
          <figure style="text-align: center;">
            <img src='figures/1-2-Fig2.png' alt='frontdoor-criterion' width="300" />
            <figcaption style="font-size: small;">Figure 2.2</figcaption>
          </figure>
        </p>
        <div class="theorem">
          <h5>Front-Door Criterion Definition (Pearl 2009):</h5>
          A set of variables \(M\) satisfies the front-door criterion relative to \(X, Y\) and \(Y\) if
          <ul>
            <li>\(M\) mediates all directed paths from \(X\) to \(Y\) </li>
            <li>there is no unblocked back-door path from \(X\) to \(M\)</li>
            <li>all back-door paths from \(M\) to \(Y\) are blocked by \(X\)</li>
          </ul>
        </div>
        <p>This definition is followed by</p>        
        
        <div class="theorem">
          <h5>Front-Door Adjustment Theorem (Pearl 2009):</h5>
          If \(M\) satisfies the front-door criterion relative to (\(X,Y\)) and \(P(x, m) > 0\), the causal effect of \(X\) on \(Y\) is identified as
          $$P(y|do(x)) = \sum_{m}P(m|x)\sum_{x'}P(y|x',z)P(x')$$
        </div>
        <p>
          With \(M\) being a front-door criterion, the causal effect can be determined through the following steps (Pearl 2009; Neal 2020) 
        </p>
        <h5>Step 1: Identify the causal effect of \(X\) on \(M\)</h5>
        <p>
          Notice that \(Y\) is a collider blocking the back-door path \(X \leftarrow Z \rightarrow Y \leftarrow M\). \(X \rightarrow M\) is the direct causal path.
          $$P(m|do(x) = P(m|t))$$
        </p>
        <h5>Step 2: Identify the causal effect of \(M\) on \(Y\)</h5>
        <p>
          The back-door path \(M \leftarrow X \leftarrow Z \rightarrow Y\) can be blocked by conditioning on \(X\). In other words, we can use Back-door Adjustment on \(X\).
          $$P(y|do(m) = \sum_{x'}P(y|m, x')P(x'))$$
          We use \(x'\) to distinguish this random value with the interventional value \(X=x\)
        </p>
        <h5>Step 3: Combine the two effects to identify the causal effect of \(X\) on \(Y\)</h5>
        <p>
          By first setting \(X=x\), we observe the value \(M=m\). We then set \(M\) to this value \(m\) and evaluate \(Y\).
          If \(M=m\) every time we set \(X\) to \(x\), the combined effect would be exactly \(P(y|do(m)\). 
          In fact, \(M\) returns multiple values \(m\) corresponding to \(X=x\) with probability \(P(m|do(x))\). 
          Thus, the combined effect is generally calculated by summing the effects on \(Y\) observed when \(M=m\) weighted by the probablity that value \(m\) occurs. 
          $$P(y|do(x)) = \sum_{m}P(m|do(x)P(y|do(m))$$
          Substituting the results from step (1) and (2) yield the theorem, in which all quantities can be estimated. 
        </p>

        <h3 id="2.3">2.3. \(Do\) Calculus</h3>
        <p>
          \(Do\) calculus is a set of general inference rules that are proved to be sufficient to identify all causal estimands given that they are identifiable. 
          These rules not only generalize the <strong>Back-door criterion</strong> and <strong>Front-door criterion</strong>, but is also valid when neither criteria is satisfied.  
          Detailed explanation can be best found in Section 3.4 of <i>Causality</i> book (Pearl 2009) or less formal in Section 6.2 of the <i>Introduction to Causal Inference</i> book (Neal 2020).
          I here only introduce the rules and convey a slightly different intuition to aid your understanding.
        </p>
        <p>
          Given a causal DAG \(G\), we denote \(G_{\bar{X}}\) the graph obtained by deleting from \(G\) all incoming paths to nodes in \(X\).
          We denote \(G_{\underline{X}}\) the graph obtained by deleting from \(G\) all outgoing paths from nodes in \(X\). 
          The question is still to establish the causal path from \(X\) to \(Y\), so we start with graph \(G_{\bar{X}}\) which is equivalent to the manipulated graph induced by the intervention \(do(X)=x\).  
          For any <span style="text-decoration: underline;">disjoint</span> subsets of variables \(X,Y,Z,W\), we have the following rules
        </p>
        <div class="theorem">
          <h5>\(Do\) Calculus Theorem (Pearl 2009)</h5>
          <p>
            <h6>Rule 1: Insertion/Deletion of observations</h6>
            $$P(y|do(x),z,w) = P(y|do(x),w) \quad if \quad (Y \perp Z)|X,W \quad w.r.t \quad G_{\bar{X}}$$
          </p>    
        </div>
        <p>
          One easy way to look at this is to ignore the term \(do(X)\), roughly since we must add \(X\) to the condition set since we are fixated on \(G_{\bar{X}}\). 
          \(Y\) is independent of \(Z\) given {\(X,W\)}, so \(z\) gives no additional information. 
          This means adjusting {\(X,W\)} blocks all possible back-door paths \(Y-Z\), which may be confused with the true causal path.
          \(Z\) thus then becomes irrelevant and can be removed or included freely. Rule 1 also confirms \(d\)-separation.
        </p>
        <div class="theorem">
          <h5>\(Do\) Calculus Theorem (Pearl 2009)</h5>
          <p>
            <h6>Rule 2: Action/Observation change</h6>
            $$P(y|do(x),do(z),w) = P(y|do(x),z,w) \quad if \quad (Y \perp Z)|X,W \quad w.r.t \quad G_{\bar{X}\underline{Z}}$$
          </p>    
        </div>
        <p>
          Recall that we are still working on the manipulated graph \(G_{\bar{X}}\). The extra condition of \(G_{\underline{Z}}\) ensures \(Z\) has no children, 
          so there cannot be any direct path from \(Z\) to \(Y\). \(Z\) is by no means a cause \(Y\) in \(G_{\bar{X}\underline{Z}}\). 
          Thus, any changes in \(Z\) resulting in changes in \(Y\) are merely statistical correlations. 
        </p>
        <div class="theorem">
          <h5>\(Do\) Calculus Theorem (Pearl 2009)</h5>
          <p>
            <h6>Rule 3: Insertion/Deletion of actions</h6>
            $$P(y|do(x),do(z),w) = P(y|do(x),w) \quad if \quad (Y \perp Z)|X,W \quad w.r.t \quad G_{\overline{XZ(W)}}$$
            where \(Z(W)\) is the set of \(Z\)-nodes that are not ancestors of any \(W\)-node in \(G_{\bar{X}}\)    
          </p>
        </div>
        <p>
          Let \(\widetilde{Z(W)}\) denote the set of \(Z\)-nodes that can be ancestors of \(W\). Because \(Z(W)\) can neither have parents nor be an ancestor of \(W\), 
          without passing through \(\widetilde{Z(W)}\), \(Z(W)\) can only connect with \(W\) and indirectly with \(Y\) through a collider, which automatically blocks the path.  
          Safely ignoring \(do(X)\), the fact that \(Y\) and \(Z\) becomes independent given \(W\) means that either (1) \(Y,Z\) are independent to begin with, 
          or (2) all paths between \(Y\) and \(\widetilde{Z(W)}\) must go through \(W\) where \(W\) is a chain or a fork by \(d\)-separation. 
          For a causal effect to take place, one such path must contain arrows pointing from \(\widetilde{Z(W)}\) towards \(Y\), and the path is blocked by \(W\) in this case. 
          Thus in all cases, intervening on \(Z\) does not affect \(Y\) at all.
        </p>
        <h3 id="2.4">2.4. Structural Causal Models (Coming Soon)</h3>
        <h3 id="2.4">2.5. Instrumental Variables (Coming Soon)</h3>
        <h3 id="2.5">2.6. Mediation Analysis (Coming Soon)</h3>
        
    
    </article>
    </div>
    <div style="text-align: center; padding-top: 20px;">
      <a href="1-1-preliminaries.html" class="navbutton">&#9664 Chapter 1. Preliminaries</a>
       <a href="#" class="navbutton">&#128274 Chapter 3. A Bigger Picture </a> <!-- &#9654 -->
       
    </div>
    <div class="wrapper-footer">
        <div class="container">
        <footer class="footer">


        <a href="https://www.facebook.com/isVy08"><i class="svg-icon facebook"></i></a>        
        <a href="https://twitter.com/isVy08"><i class="svg-icon twitter"></i></a>
        <a href="https://www.linkedin.com/in/isvy08/"><i class="svg-icon linkedin"></i></a>
        <br><p style="font-size: 10px;">&copy; 2021 Vy Vo. Powered by Jekyll and Jekyll Now Theme</p>   

        </footer>
        </div>
    </div> 
</body>
</html>
